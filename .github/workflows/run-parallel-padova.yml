name: Run parallel Offloading Padova

on:
  workflow_call:
    inputs:
      image_name:
        description: "Name of the .sif container"
        required: true
        type: string      
      macro_splits:
        description: "Number of splits for each macro"
        required: false
        default: 5
        type: number

jobs:
  get-macros:
    runs-on: geant-gha-runner-on-padova
    outputs:
      matrix: ${{ steps.expand.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: List macro files and expand matrix
        id: expand
        run: |
          PARTS=${{ inputs.macro_splits }}
          # List all .mac files excluding macro/unit.mac          
          MACROS=$(find macro/ -name "*.mac" -type f -printf '%P\n' | grep -v "^unit\.mac$")

          # Build a JSON object with an "include" array for the dynamic matrix
          MATRIX='{"include":['
          for MACRO in $MACROS; do
            for i in $(seq 0 $((PARTS-1))); do
              MATRIX="$MATRIX{\"macro\":\"$MACRO\",\"part\":$i},"
            done
          done
          MATRIX="${MATRIX%,}]}"   # close the array and the object

          echo "matrix=$MATRIX" >> "$GITHUB_OUTPUT"

  run-part:
    needs: get-macros
    runs-on: geant-gha-runner-on-padova
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.get-macros.outputs.matrix) }}
    env:
      APPTAINER_CACHEDIR: /tmp/apptainer_cache
      APPTAINER_TMPDIR: /tmp/apptainer_tmp
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Prepare Apptainer cache in /tmp
        run: |
          mkdir -p "$APPTAINER_CACHEDIR" "$APPTAINER_TMPDIR"
          echo "Using APPTAINER_CACHEDIR=$APPTAINER_CACHEDIR"
          echo "Using APPTAINER_TMPDIR=$APPTAINER_TMPDIR"
          df -h /tmp || true
        
      - name: Setup Environment Variables
        id: setup
        run: |
          echo "tag=${GITHUB_SHA}" >> "$GITHUB_OUTPUT"
          repo_lower=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
          echo "repo_lower=${repo_lower}" >> "$GITHUB_OUTPUT"

      - name: Login to GHCR
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}        
        run: |
          echo "$GITHUB_TOKEN" | apptainer registry login -u "${{ github.actor }}" --password-stdin oras://ghcr.io

      - name: Pull Container from GHCR
        run: |
          IMAGE_URI="oras://ghcr.io/${{ steps.setup.outputs.repo_lower }}:${{ steps.setup.outputs.tag }}"
          echo "Pulling from: $IMAGE_URI"
          apptainer pull --force /tmp/runner/${{ inputs.image_name }} "$IMAGE_URI"
          
      - name: Prepare apptainer command
        run: |
          cat <<EOF > /tmp/runner/run
          apptainer run \
            --unsquash \
            -B /cvmfs/geant4.cern.ch/share/data:/opt/geant4/data \
            -B "/tmp/macros:/macro" \
            -B "/tmp/outputs:/outputs" \
            /tmp/runner/${{ inputs.image_name }} \
            "\$@"
          EOF
          chmod +x /tmp/runner/run
          mkdir -p /tmp/outputs /tmp/macros
          
      - name: Generate modified macro
        run: |
          INMACRO="macro/${{ matrix.macro }}"
          OUTMACRO="/tmp/macros/part-${{ matrix.part }}.mac"
          OUTFILE="/outputs/part_${{ matrix.part }}.xml"
          SEED=$((1000 + ${{ matrix.part }}))

          TOTAL_EVENTS=$(awk '$1=="/run/beamOn"{print $2; exit}' "$INMACRO")          
          SPLITS=${{ inputs.macro_splits }}          
          EVENTS=$((TOTAL_EVENTS / SPLITS))
          
          sed \
            -e "s|/outputs/.*\.xml|$OUTFILE|" \
            -e "/\/run\/beamOn/ c\/run\/beamOn $EVENTS" \
            -e "\$a\/random/setSeeds $SEED $SEED" \
            "$INMACRO" > "$OUTMACRO"

          echo "out_macro=$OUTMACRO" >> $GITHUB_ENV

      - name: Run container with modified macro
        run: |
          cd /tmp/runner
          MACRO_NAME=$(basename "$out_macro")
          MACRO_IN_CONTAINER="/macro/$MACRO_NAME"
          echo "Running LowEFrag with macro in container: $MACRO_IN_CONTAINER"
          ./run "$MACRO_IN_CONTAINER"

      - name: Verify output file was produced
        run: |
          OUTPUT_FILE="/tmp/outputs/${{ env.out_basename }}.xml"
          echo "Checking for output file: $OUTPUT_FILE"
          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "ERROR: Expected output file not found: $OUTPUT_FILE" >&2
            echo "The container run completed, but no output file was produced." >&2
            exit 1
          fi
          
      - name: Upload output artifact for part
        uses: actions/upload-artifact@v4
        with:
          name: partial-${{ matrix.macro }}-${{ matrix.part }}
          path: /tmp/outputs/part_${{ matrix.part }}.xml

      - name: Cleanup Apptainer cache in /tmp
        if: always()
        run: |
          rm -rf "$APPTAINER_CACHEDIR" "$APPTAINER_TMPDIR" || true
          
  merge-parts:
    needs: run-part
    runs-on: geant-gha-runner-on-padova
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all part artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
        continue-on-error: true   

      - name: Merge AIDA XML outputs
        run: |
          mkdir -p merged

          if [ ! -d artifacts ]; then
            echo "No artifacts directory found, nothing to merge."
            exit 0
          fi

          files=$(find artifacts -name '*.xml' -print)

          if [ -z "$files" ]; then
            echo "No XML files found in artifacts, nothing to merge."
            exit 0
          fi

          echo "Merging the following files:"
          printf '%s\n' $files

          python3 .github/scripts/merge_aida.py $files > merged/merged.xml

      - name: Upload final merged output
        if: success() 
        uses: actions/upload-artifact@v4
        with:
          name: final-merged-output
          path: merged/merged.xml
